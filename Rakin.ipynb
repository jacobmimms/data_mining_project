{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "This notebook is for me, Rakin, just to analyze the data. I avoided creating a .py file for this because I wanted to be able to use the notebook to write my thoughts and ideas. I will try to keep this notebook as clean as possible for anyone to jump in add their ideas to the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read & Clean the data \n",
    "Here the Data will be stored in Pandas checked for outliers, strange values etc before starting the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Convert the Data CSV files to pandas\n",
    "print(\"Reading Books Data...\")\n",
    "books_data = pd.read_csv(\"Data/BX-Books.csv\", sep=';', on_bad_lines='skip', encoding=\"latin\")\n",
    "print(\"Readting Users Data...\")\n",
    "users_data = pd.read_csv(\"Data/BX-Users.csv\", sep=';', on_bad_lines='skip', encoding=\"latin\")\n",
    "print(\"Reading Ratings Data...\")\n",
    "book_ratings = pd.read_csv(\"Data/BX-Book-Ratings.csv\", sep=';', on_bad_lines='skip', encoding=\"latin\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Books Data\n",
    "Doing a massive cleaning of books_data.csv. \n",
    "1. Removing all the books that have no ISBN\n",
    "2. Removing all the books that have no author\n",
    "3. Removing all the books that have no title\n",
    "4. Removing all the books that have no publisher\n",
    "5. Removing all the books that have no year of publication or 0 as year of publication\n",
    "6. Removing all the books that have no image url\n",
    "7. Removing all the books that have no image url small\n",
    "8. Removing all the books that have no image url medium\n",
    "9. Removing all the books that have no image url large\n",
    "10. Removing all books that have no description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out which columns have mixed types\n",
    "print(\"Total number of rows in the dataset is: \", len(books_data))\n",
    "print(\"Total number of unique ISBNs is: \", len(books_data['ISBN'].unique()))\n",
    "\n",
    "# In Book-Author, there are some values that are not strings. Drop their rows from the dataset\n",
    "books_data = books_data.loc[books_data['Book-Author'].apply(lambda x: isinstance(x, str)), :]\n",
    "books_data = books_data.loc[books_data['Year-Of-Publication'].apply(lambda x: isinstance(x, int)), :]\n",
    "books_data = books_data.loc[books_data['Year-Of-Publication'].apply(lambda x: x != 0), :]\n",
    "books_data = books_data.loc[books_data['Publisher'].apply(lambda x: isinstance(x, str)), :]\n",
    "books_data = books_data.loc[books_data['Image-URL-S'].apply(lambda x: isinstance(x, str)), :]\n",
    "books_data = books_data.loc[books_data['Image-URL-M'].apply(lambda x: isinstance(x, str)), :]\n",
    "books_data = books_data.loc[books_data['Image-URL-L'].apply(lambda x: isinstance(x, str)), :]\n",
    "books_data.dropna(inplace=True)\n",
    "books_data.reset_index(drop=True, inplace=True)\n",
    "print(\"Total number of rows in the dataset is: \", len(books_data))\n",
    "\n",
    "# Grab all the ISBNs that been rated over 20 times in books_data\n",
    "print(\"Delete all the ISBNs that have been rated less than 20 times from the dataset...\")\n",
    "ISBNs = book_ratings['ISBN'].value_counts()\n",
    "ISBNs = ISBNs[ISBNs >= 20]\n",
    "ISBNs = ISBNs.index.tolist()\n",
    "books_data = books_data.loc[books_data['ISBN'].apply(lambda x: x in ISBNs), :]\n",
    "books_data.reset_index(drop=True, inplace=True)\n",
    "print(\"Books that have been rated more than 20 times: \", len(books_data))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Book rating and User data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all ISBNs that were removed from books_data to book_ratings\n",
    "print(\"Removing all the ISBNs that have been removed from the books_data dataset to the book_ratings dataset...\")\n",
    "valid_ISBNs = set(ISBNs)\n",
    "book_ratings = book_ratings[book_ratings['ISBN'].isin(valid_ISBNs)].reset_index(drop=True)\n",
    "\n",
    "# Remove the row from book_rating if a user rated a book a 0\n",
    "print(\"Removing all the rows from book_ratings if a user rated a book a 0...\")\n",
    "nonzero_mask = book_ratings['Book-Rating'] != 0\n",
    "book_ratings = book_ratings[nonzero_mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Removing all the users that have rated less than 5 books from the book_data dataset and their ISBN...\")\n",
    "users = book_ratings['User-ID'].value_counts()\n",
    "users = users[users >= 4]\n",
    "users = users.index.tolist()\n",
    "book_ratings = book_ratings.loc[book_ratings['User-ID'].apply(lambda x: x in users), :]\n",
    "book_ratings.reset_index(drop=True, inplace=True)\n",
    "print(\"Total number of users that gave a rating of at leat 4 books is: \", len(users))\n",
    "\n",
    "\n",
    "# If ISBN is in book_ratings and in books_data, keep it in books_data. Otherwise, drop it from books_data\n",
    "ISBNs = None\n",
    "ISBNs = book_ratings['ISBN'].value_counts()\n",
    "ISBNs = ISBNs.index.tolist()\n",
    "books_data = books_data.loc[books_data['ISBN'].apply(lambda x: x in ISBNs), :]\n",
    "books_data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out total books, users and ratings\n",
    "print(\"Total books: \", len(books_data['ISBN'].unique()))\n",
    "print(\"Total users: \", len(book_ratings['User-ID'].unique()))\n",
    "print(\"Total ratings: \", len(book_ratings))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the matrix for the recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab all the ISBNs in the books_data and user s in the book_ratings\n",
    "ISBNs_filtered = books_data['ISBN'].unique().tolist()\n",
    "users_filtered = book_ratings['User-ID'].unique().tolist()\n",
    "\n",
    "\n",
    "# Create a dataframe where the Index is the User-ID and the columns are the ISBNs\n",
    "print(\"Creating a dataframe where the Index is the User-ID and the columns are the ISBNs...\")\n",
    "matrix = pd.DataFrame(index=users_filtered, columns=ISBNs_filtered)\n",
    "matrix.fillna(0, inplace=True)\n",
    "print(\"The rows of the matrix are the users: \", matrix.shape[0])\n",
    "\n",
    "\n",
    "# Fill the matrix with the ratings\n",
    "for i in range(len(book_ratings)):\n",
    "  user = book_ratings.iloc[i]['User-ID']\n",
    "  ISBN = book_ratings.iloc[i]['ISBN']\n",
    "  rating = book_ratings.iloc[i]['Book-Rating']\n",
    "  matrix.at[user, ISBN] = rating\n",
    "\n",
    "# Turn the NaN values to 0\n",
    "matrix.fillna(0, inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting the collaborative filtering\n",
    "\n",
    "First we are doing a cosine similarity matrix for the books. This will be used to find the most similar books to a given book and then recommend those books to the user.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do cosine similarity\n",
    "print(\"Doing cosine similarity...\")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_sim = cosine_similarity(matrix, matrix)\n",
    "\n",
    "# Turn the cosine_sim into a dataframe\n",
    "cosine_sim = pd.DataFrame(cosine_sim, index=matrix.index, columns=matrix.index)\n",
    "\n",
    "# Visualize the cosine_sim\n",
    "print(\"Visualizing the cosine_sim...\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cosine_sim.iloc[:100, :100], cmap='coolwarm')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
