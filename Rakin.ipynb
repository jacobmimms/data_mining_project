{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "This notebook is for me, Rakin, just to analyze the data. I avoided creating a .py file for this because I wanted to be able to use the notebook to write my thoughts and ideas. I will try to keep this notebook as clean as possible for anyone to jump in add their ideas to the project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read & Clean the data \n",
    "Here the Data will be stored in Pandas checked for outliers, strange values etc before starting the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Books Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rakin\\AppData\\Local\\Temp\\ipykernel_36364\\1206900022.py:13: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books_data = pd.read_csv(\"Data/BX-Books.csv\", sep=';', on_bad_lines='skip', encoding=\"latin\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readting Users Data...\n",
      "Reading Ratings Data...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Convert the Data CSV files to pandas\n",
    "print(\"Reading Books Data...\")\n",
    "books_data = pd.read_csv(\"Data/BX-Books.csv\", sep=';', on_bad_lines='skip', encoding=\"latin\")\n",
    "print(\"Readting Users Data...\")\n",
    "users_data = pd.read_csv(\"Data/BX-Users.csv\", sep=';', on_bad_lines='skip', encoding=\"latin\")\n",
    "print(\"Reading Ratings Data...\")\n",
    "book_ratings = pd.read_csv(\"Data/BX-Book-Ratings.csv\", sep=';', on_bad_lines='skip', encoding=\"latin\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Books Data\n",
    "Doing a massive cleaning of books_data.csv. \n",
    "1. Removing all the books that have no ISBN\n",
    "2. Removing all the books that have no author\n",
    "3. Removing all the books that have no title\n",
    "4. Removing all the books that have no publisher\n",
    "5. Removing all the books that have no year of publication or 0 as year of publication\n",
    "6. Removing all the books that have no image url\n",
    "7. Removing all the books that have no image url small\n",
    "8. Removing all the books that have no image url medium\n",
    "9. Removing all the books that have no image url large\n",
    "10. Removing all books that have no description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the dataset is:  205821\n",
      "Total number of unique ISBNs is:  205821\n",
      "Total number of rows in the dataset is:  205821\n",
      "Delete all the ISBNs that have been rated less than 20 times from the dataset...\n",
      "Total number of rows in the dataset is:  6863\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7064"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out which columns have mixed types\n",
    "print(\"Total number of rows in the dataset is: \", len(books_data))\n",
    "print(\"Total number of unique ISBNs is: \", len(books_data['ISBN'].unique()))\n",
    "\n",
    "# In Book-Author, there are some values that are not strings. Drop their rows from the dataset\n",
    "books_data = books_data.loc[books_data['Book-Author'].apply(lambda x: isinstance(x, str)), :]\n",
    "books_data = books_data.loc[books_data['Year-Of-Publication'].apply(lambda x: isinstance(x, int)), :]\n",
    "books_data = books_data.loc[books_data['Publisher'].apply(lambda x: isinstance(x, str)), :]\n",
    "books_data = books_data.loc[books_data['Image-URL-S'].apply(lambda x: isinstance(x, str)), :]\n",
    "books_data = books_data.loc[books_data['Image-URL-M'].apply(lambda x: isinstance(x, str)), :]\n",
    "books_data = books_data.loc[books_data['Image-URL-L'].apply(lambda x: isinstance(x, str)), :]\n",
    "books_data.dropna(inplace=True)\n",
    "books_data.reset_index(drop=True, inplace=True)\n",
    "print(\"Total number of rows in the dataset is: \", len(books_data))\n",
    "\n",
    "# Grab all the ISBNs that been rated over 20 times in books_data\n",
    "print(\"Delete all the ISBNs that have been rated less than 20 times from the dataset...\")\n",
    "ISBNs = book_ratings['ISBN'].value_counts()\n",
    "ISBNs = ISBNs[ISBNs > 20]\n",
    "ISBNs = ISBNs.index.tolist()\n",
    "books_data = books_data.loc[books_data['ISBN'].apply(lambda x: x in ISBNs), :]\n",
    "books_data.reset_index(drop=True, inplace=True)\n",
    "print(\"Total number of rows in the dataset is: \", len(books_data))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning users data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing all the users that have rated less than 5 books from the book_data dataset and their ISBN\n",
      "Removing all the ISBNs that are not in the book_ratings dataset from the book_data dataset...\n",
      "Total number of rows in the dataset is:  6863\n"
     ]
    }
   ],
   "source": [
    "print(\"Removing all the users that have rated less than 5 books from the book_data dataset and their ISBN\")\n",
    "users = book_ratings['User-ID'].value_counts()\n",
    "users = users[users > 5]\n",
    "users = users.index.tolist()\n",
    "book_ratings = book_ratings.loc[book_ratings['User-ID'].apply(lambda x: x in users), :]\n",
    "book_ratings.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# If ISBN is in book_ratings and in books_data, then keep it in books_data. Otherwise, drop it from books_data\n",
    "ISBNs = book_ratings['ISBN'].value_counts()\n",
    "ISBNs = ISBNs.index.tolist()\n",
    "books_data = books_data.loc[books_data['ISBN'].apply(lambda x: x in ISBNs), :]\n",
    "books_data.reset_index(drop=True, inplace=True)\n",
    "print(\"Total number of rows in the dataset is: \", len(books_data))\n",
    "\n",
    "# books_data is now ready to be used for the recommendation system\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
