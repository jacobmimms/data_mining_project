{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "Based on Rakin's preprocessing to do the item-based collaborative filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read & Clean the data \n",
    "Here the Data will be stored in Pandas checked for outliers, strange values etc before starting the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Convert the Data CSV files to pandas\n",
    "print(\"Reading Books Data...\")\n",
    "books_data = pd.read_csv(\"Data/BX-Books.csv\", sep=';', on_bad_lines='skip', encoding=\"latin\")\n",
    "print(\"Readting Users Data...\")\n",
    "users_data = pd.read_csv(\"Data/BX-Users.csv\", sep=';', on_bad_lines='skip', encoding=\"latin\")\n",
    "print(\"Reading Ratings Data...\")\n",
    "book_ratings = pd.read_csv(\"Data/BX-Book-Ratings.csv\", sep=';', on_bad_lines='skip', encoding=\"latin\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Books Data\n",
    "Doing a massive cleaning of books_data.csv. \n",
    "1. Removing all the books that have no ISBN\n",
    "2. Removing all the books that have no author\n",
    "3. Removing all the books that have no title\n",
    "4. Removing all the books that have no publisher\n",
    "5. Removing all the books that have no year of publication or 0 as year of publication\n",
    "6. Removing all the books that have no image url\n",
    "7. Removing all the books that have no image url small\n",
    "8. Removing all the books that have no image url medium\n",
    "9. Removing all the books that have no image url large\n",
    "10. Removing all books that have no description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out which columns have mixed types\n",
    "print(\"Total number of rows in the dataset is: \", len(books_data))\n",
    "print(\"Total number of unique ISBNs is: \", len(books_data['ISBN'].unique()))\n",
    "\n",
    "# In Book-Author, there are some values that are not strings. Drop their rows from the dataset\n",
    "books_data = books_data.loc[books_data['Book-Author'].apply(lambda x: isinstance(x, str)), :]\n",
    "books_data = books_data.loc[books_data['Year-Of-Publication'].apply(lambda x: isinstance(x, int)), :]\n",
    "books_data = books_data.loc[books_data['Year-Of-Publication'].apply(lambda x: x != 0), :]\n",
    "books_data = books_data.loc[books_data['Publisher'].apply(lambda x: isinstance(x, str)), :]\n",
    "books_data = books_data.loc[books_data['Image-URL-S'].apply(lambda x: isinstance(x, str)), :]\n",
    "books_data = books_data.loc[books_data['Image-URL-M'].apply(lambda x: isinstance(x, str)), :]\n",
    "books_data = books_data.loc[books_data['Image-URL-L'].apply(lambda x: isinstance(x, str)), :]\n",
    "books_data.dropna(inplace=True)\n",
    "books_data.reset_index(drop=True, inplace=True)\n",
    "print(\"Total number of rows in the dataset is: \", len(books_data))\n",
    "\n",
    "# Grab all the ISBNs that been rated over 20 times in books_data\n",
    "print(\"Delete all the ISBNs that have been rated less than 20 times from the dataset...\")\n",
    "ISBNs = book_ratings['ISBN'].value_counts()\n",
    "ISBNs = ISBNs[ISBNs >= 20]\n",
    "ISBNs = ISBNs.index.tolist()\n",
    "books_data = books_data.loc[books_data['ISBN'].apply(lambda x: x in ISBNs), :]\n",
    "books_data.reset_index(drop=True, inplace=True)\n",
    "print(\"Books that have been rated more than 20 times: \", len(books_data))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Book rating and User data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all ISBNs that were removed from books_data to book_ratings\n",
    "print(\"Removing all the ISBNs that have been removed from the books_data dataset to the book_ratings dataset...\")\n",
    "valid_ISBNs = set(ISBNs)\n",
    "book_ratings = book_ratings[book_ratings['ISBN'].isin(valid_ISBNs)].reset_index(drop=True)\n",
    "\n",
    "# Remove the row from book_rating if a user rated a book a 0\n",
    "print(\"Removing all the rows from book_ratings if a user rated a book a 0...\")\n",
    "nonzero_mask = book_ratings['Book-Rating'] != 0\n",
    "book_ratings = book_ratings[nonzero_mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Removing all the users that have rated less than 5 books from the book_data dataset and their ISBN...\")\n",
    "users = book_ratings['User-ID'].value_counts()\n",
    "users = users[users >= 4]\n",
    "users = users.index.tolist()\n",
    "book_ratings = book_ratings.loc[book_ratings['User-ID'].apply(lambda x: x in users), :]\n",
    "book_ratings.reset_index(drop=True, inplace=True)\n",
    "print(\"Total number of users that gave a rating of at leat 4 books is: \", len(users))\n",
    "\n",
    "\n",
    "# If ISBN is in book_ratings and in books_data, keep it in books_data. Otherwise, drop it from books_data\n",
    "ISBNs = None\n",
    "ISBNs = book_ratings['ISBN'].value_counts()\n",
    "ISBNs = ISBNs.index.tolist()\n",
    "books_data = books_data.loc[books_data['ISBN'].apply(lambda x: x in ISBNs), :]\n",
    "books_data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out total books, users and ratings\n",
    "print(\"Total books: \", len(books_data['ISBN'].unique()))\n",
    "print(\"Total users: \", len(book_ratings['User-ID'].unique()))\n",
    "print(\"Total ratings: \", len(book_ratings))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the matrix for the recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab all the ISBNs in the books_data and user s in the book_ratings\n",
    "ISBNs_filtered = books_data['ISBN'].unique().tolist()\n",
    "users_filtered = book_ratings['User-ID'].unique().tolist()\n",
    "\n",
    "\n",
    "# Create a dataframe where the Index is the User-ID and the columns are the ISBNs\n",
    "print(\"Creating a dataframe where the Index is the User-ID and the columns are the ISBNs...\")\n",
    "matrix = pd.DataFrame(index=users_filtered, columns=ISBNs_filtered)\n",
    "matrix.fillna(0, inplace=True)\n",
    "print(\"The rows of the matrix are the users: \", matrix.shape[0])\n",
    "\n",
    "\n",
    "# Fill the matrix with the ratings\n",
    "for i in range(len(book_ratings)):\n",
    "  user = book_ratings.iloc[i]['User-ID']\n",
    "  ISBN = book_ratings.iloc[i]['ISBN']\n",
    "  rating = book_ratings.iloc[i]['Book-Rating']\n",
    "  matrix.at[user, ISBN] = rating\n",
    "\n",
    "# Turn the NaN values to 0\n",
    "matrix.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# item-based collaborative filtering\n",
    "\n",
    "First do item-based collaborative filtering using traditional method based on users' ratings and cosine similarity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do cosine similarity bewtween 2 books\n",
    "def computeItemSimilarity(book1,book2,avg):\n",
    "   num = 0\n",
    "   dem1 = 0\n",
    "   dem2 = 0\n",
    "   for user in book1.index:\n",
    "      num += (book1[user] - avg[user]) * (book2[user] - avg[user])\n",
    "      dem1 += (book1[user] - avg)**2\n",
    "      dem2 += (book1[user] - avg)**2\n",
    "   return num / (np.sqrt(dem1) * np.sqrt(dem2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_matrix = pd.DataFrame(index = matrix.columns, columns = matrix.columns)\n",
    "mean = matrix.mean(axis=1)\n",
    "for idx in range(len(item_matrix-1)):\n",
    "    print(idx)\n",
    "    for idx2 in range(len(item_matrix-1)):\n",
    "        item_matrix.iloc[idx,idx2] = computeItemSimilarity(matrix.iloc[:,idx],matrix.iloc[:,idx2],mean)\n",
    "item_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
